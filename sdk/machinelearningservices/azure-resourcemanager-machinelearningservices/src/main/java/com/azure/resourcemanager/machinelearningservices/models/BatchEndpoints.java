// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.resourcemanager.machinelearningservices.models;

import com.azure.core.http.rest.PagedIterable;
import com.azure.core.http.rest.Response;
import com.azure.core.util.Context;

/** Resource collection API of BatchEndpoints. */
public interface BatchEndpoints {
    /**
     * Gets a batch inference endpoint by name.
     *
     * @param endpointName Name for the Batch Endpoint.
     * @param resourceGroupName Name of the resource group in which workspace is located.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a batch inference endpoint by name.
     */
    BatchEndpointTrackedResource get(String endpointName, String resourceGroupName, String workspaceName);

    /**
     * Gets a batch inference endpoint by name.
     *
     * @param endpointName Name for the Batch Endpoint.
     * @param resourceGroupName Name of the resource group in which workspace is located.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a batch inference endpoint by name.
     */
    Response<BatchEndpointTrackedResource> getWithResponse(
        String endpointName, String resourceGroupName, String workspaceName, Context context);

    /**
     * Delete Batch Inference Endpoint.
     *
     * @param endpointName Inference Endpoint name.
     * @param resourceGroupName Name of the resource group in which workspace is located.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     */
    void delete(String endpointName, String resourceGroupName, String workspaceName);

    /**
     * Delete Batch Inference Endpoint.
     *
     * @param endpointName Inference Endpoint name.
     * @param resourceGroupName Name of the resource group in which workspace is located.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    Response<Void> deleteWithResponse(
        String endpointName, String resourceGroupName, String workspaceName, Context context);

    /**
     * Lists Batch inference endpoint in the workspace.
     *
     * @param resourceGroupName Name of the resource group in which workspace is located.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a paginated list of BatchEndpoint entities.
     */
    PagedIterable<BatchEndpointTrackedResource> list(String resourceGroupName, String workspaceName);

    /**
     * Lists Batch inference endpoint in the workspace.
     *
     * @param resourceGroupName Name of the resource group in which workspace is located.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param skiptoken Continuation token for pagination.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a paginated list of BatchEndpoint entities.
     */
    PagedIterable<BatchEndpointTrackedResource> list(
        String resourceGroupName, String workspaceName, String skiptoken, Context context);

    /**
     * Lists batch Inference Endpoint keys.
     *
     * @param endpointName Inference Endpoint name.
     * @param resourceGroupName Name of the resource group in which workspace is located.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    InferenceEndpointKeysTrackedResource listKeys(String endpointName, String resourceGroupName, String workspaceName);

    /**
     * Lists batch Inference Endpoint keys.
     *
     * @param endpointName Inference Endpoint name.
     * @param resourceGroupName Name of the resource group in which workspace is located.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    Response<InferenceEndpointKeysTrackedResource> listKeysWithResponse(
        String endpointName, String resourceGroupName, String workspaceName, Context context);

    /**
     * Gets a batch inference endpoint by name.
     *
     * @param id the resource ID.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a batch inference endpoint by name.
     */
    BatchEndpointTrackedResource getById(String id);

    /**
     * Gets a batch inference endpoint by name.
     *
     * @param id the resource ID.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a batch inference endpoint by name.
     */
    Response<BatchEndpointTrackedResource> getByIdWithResponse(String id, Context context);

    /**
     * Delete Batch Inference Endpoint.
     *
     * @param id the resource ID.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     */
    void deleteById(String id);

    /**
     * Delete Batch Inference Endpoint.
     *
     * @param id the resource ID.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    Response<Void> deleteByIdWithResponse(String id, Context context);

    /**
     * Begins definition for a new BatchEndpointTrackedResource resource.
     *
     * @param name resource name.
     * @return the first stage of the new BatchEndpointTrackedResource definition.
     */
    BatchEndpointTrackedResource.DefinitionStages.Blank define(String name);
}
