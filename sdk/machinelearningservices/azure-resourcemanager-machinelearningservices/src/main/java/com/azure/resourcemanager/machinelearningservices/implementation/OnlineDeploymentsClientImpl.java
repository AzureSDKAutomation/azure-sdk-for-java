// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.resourcemanager.machinelearningservices.implementation;

import com.azure.core.annotation.BodyParam;
import com.azure.core.annotation.Delete;
import com.azure.core.annotation.ExpectedResponses;
import com.azure.core.annotation.Get;
import com.azure.core.annotation.HeaderParam;
import com.azure.core.annotation.Headers;
import com.azure.core.annotation.Host;
import com.azure.core.annotation.HostParam;
import com.azure.core.annotation.Patch;
import com.azure.core.annotation.PathParam;
import com.azure.core.annotation.Post;
import com.azure.core.annotation.Put;
import com.azure.core.annotation.QueryParam;
import com.azure.core.annotation.ReturnType;
import com.azure.core.annotation.ServiceInterface;
import com.azure.core.annotation.ServiceMethod;
import com.azure.core.annotation.UnexpectedResponseExceptionType;
import com.azure.core.http.rest.PagedFlux;
import com.azure.core.http.rest.PagedIterable;
import com.azure.core.http.rest.PagedResponse;
import com.azure.core.http.rest.PagedResponseBase;
import com.azure.core.http.rest.Response;
import com.azure.core.http.rest.RestProxy;
import com.azure.core.management.exception.ManagementException;
import com.azure.core.management.polling.PollResult;
import com.azure.core.util.Context;
import com.azure.core.util.FluxUtil;
import com.azure.core.util.logging.ClientLogger;
import com.azure.core.util.polling.PollerFlux;
import com.azure.core.util.polling.SyncPoller;
import com.azure.resourcemanager.machinelearningservices.fluent.OnlineDeploymentsClient;
import com.azure.resourcemanager.machinelearningservices.fluent.models.DeploymentLogsInner;
import com.azure.resourcemanager.machinelearningservices.fluent.models.OnlineDeploymentTrackedResourceInner;
import com.azure.resourcemanager.machinelearningservices.models.DeploymentLogsRequest;
import com.azure.resourcemanager.machinelearningservices.models.OnlineDeploymentTrackedResourceArmPaginatedResult;
import com.azure.resourcemanager.machinelearningservices.models.PartialOnlineDeploymentPartialTrackedResource;
import java.nio.ByteBuffer;
import reactor.core.publisher.Flux;
import reactor.core.publisher.Mono;

/** An instance of this class provides access to all the operations defined in OnlineDeploymentsClient. */
public final class OnlineDeploymentsClientImpl implements OnlineDeploymentsClient {
    private final ClientLogger logger = new ClientLogger(OnlineDeploymentsClientImpl.class);

    /** The proxy service used to perform REST calls. */
    private final OnlineDeploymentsService service;

    /** The service client containing this operation class. */
    private final AzureMachineLearningWorkspacesImpl client;

    /**
     * Initializes an instance of OnlineDeploymentsClientImpl.
     *
     * @param client the instance of the service client containing this operation class.
     */
    OnlineDeploymentsClientImpl(AzureMachineLearningWorkspacesImpl client) {
        this.service =
            RestProxy.create(OnlineDeploymentsService.class, client.getHttpPipeline(), client.getSerializerAdapter());
        this.client = client;
    }

    /**
     * The interface defining all the services for AzureMachineLearningWorkspacesOnlineDeployments to be used by the
     * proxy service to perform REST calls.
     */
    @Host("{$host}")
    @ServiceInterface(name = "AzureMachineLearning")
    private interface OnlineDeploymentsService {
        @Headers({"Content-Type: application/json"})
        @Get(
            "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers"
                + "/Microsoft.MachineLearningServices/workspaces/{workspaceName}/onlineEndpoints/{endpointName}"
                + "/deployments")
        @ExpectedResponses({200})
        @UnexpectedResponseExceptionType(ManagementException.class)
        Mono<Response<OnlineDeploymentTrackedResourceArmPaginatedResult>> list(
            @HostParam("$host") String endpoint,
            @PathParam("endpointName") String endpointName,
            @QueryParam("api-version") String apiVersion,
            @QueryParam("$orderBy") String orderBy,
            @QueryParam("$top") Integer top,
            @QueryParam("$skip") String skip,
            @PathParam("subscriptionId") String subscriptionId,
            @PathParam("resourceGroupName") String resourceGroupName,
            @PathParam("workspaceName") String workspaceName,
            @HeaderParam("Accept") String accept,
            Context context);

        @Headers({"Content-Type: application/json"})
        @Delete(
            "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers"
                + "/Microsoft.MachineLearningServices/workspaces/{workspaceName}/onlineEndpoints/{endpointName}"
                + "/deployments/{deploymentName}")
        @ExpectedResponses({200, 202, 204})
        @UnexpectedResponseExceptionType(ManagementException.class)
        Mono<Response<Flux<ByteBuffer>>> delete(
            @HostParam("$host") String endpoint,
            @PathParam("endpointName") String endpointName,
            @PathParam("deploymentName") String deploymentName,
            @QueryParam("api-version") String apiVersion,
            @PathParam("subscriptionId") String subscriptionId,
            @PathParam("resourceGroupName") String resourceGroupName,
            @PathParam("workspaceName") String workspaceName,
            @HeaderParam("Accept") String accept,
            Context context);

        @Headers({"Content-Type: application/json"})
        @Get(
            "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers"
                + "/Microsoft.MachineLearningServices/workspaces/{workspaceName}/onlineEndpoints/{endpointName}"
                + "/deployments/{deploymentName}")
        @ExpectedResponses({200})
        @UnexpectedResponseExceptionType(ManagementException.class)
        Mono<Response<OnlineDeploymentTrackedResourceInner>> get(
            @HostParam("$host") String endpoint,
            @PathParam("endpointName") String endpointName,
            @PathParam("deploymentName") String deploymentName,
            @QueryParam("api-version") String apiVersion,
            @PathParam("subscriptionId") String subscriptionId,
            @PathParam("resourceGroupName") String resourceGroupName,
            @PathParam("workspaceName") String workspaceName,
            @HeaderParam("Accept") String accept,
            Context context);

        @Headers({"Content-Type: application/json"})
        @Patch(
            "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers"
                + "/Microsoft.MachineLearningServices/workspaces/{workspaceName}/onlineEndpoints/{endpointName}"
                + "/deployments/{deploymentName}")
        @ExpectedResponses({200, 202})
        @UnexpectedResponseExceptionType(ManagementException.class)
        Mono<Response<Flux<ByteBuffer>>> update(
            @HostParam("$host") String endpoint,
            @PathParam("endpointName") String endpointName,
            @PathParam("deploymentName") String deploymentName,
            @QueryParam("api-version") String apiVersion,
            @PathParam("subscriptionId") String subscriptionId,
            @PathParam("resourceGroupName") String resourceGroupName,
            @PathParam("workspaceName") String workspaceName,
            @BodyParam("application/json") PartialOnlineDeploymentPartialTrackedResource body,
            @HeaderParam("Accept") String accept,
            Context context);

        @Headers({"Content-Type: application/json"})
        @Put(
            "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers"
                + "/Microsoft.MachineLearningServices/workspaces/{workspaceName}/onlineEndpoints/{endpointName}"
                + "/deployments/{deploymentName}")
        @ExpectedResponses({200, 201})
        @UnexpectedResponseExceptionType(ManagementException.class)
        Mono<Response<Flux<ByteBuffer>>> createOrUpdate(
            @HostParam("$host") String endpoint,
            @PathParam("endpointName") String endpointName,
            @PathParam("deploymentName") String deploymentName,
            @QueryParam("api-version") String apiVersion,
            @PathParam("subscriptionId") String subscriptionId,
            @PathParam("resourceGroupName") String resourceGroupName,
            @PathParam("workspaceName") String workspaceName,
            @BodyParam("application/json") OnlineDeploymentTrackedResourceInner body,
            @HeaderParam("Accept") String accept,
            Context context);

        @Headers({"Content-Type: application/json"})
        @Post(
            "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers"
                + "/Microsoft.MachineLearningServices/workspaces/{workspaceName}/onlineEndpoints/{endpointName}"
                + "/deployments/{deploymentName}/getLogs")
        @ExpectedResponses({200})
        @UnexpectedResponseExceptionType(ManagementException.class)
        Mono<Response<DeploymentLogsInner>> getLogs(
            @HostParam("$host") String endpoint,
            @PathParam("endpointName") String endpointName,
            @PathParam("deploymentName") String deploymentName,
            @QueryParam("api-version") String apiVersion,
            @PathParam("subscriptionId") String subscriptionId,
            @PathParam("resourceGroupName") String resourceGroupName,
            @PathParam("workspaceName") String workspaceName,
            @BodyParam("application/json") DeploymentLogsRequest body,
            @HeaderParam("Accept") String accept,
            Context context);

        @Headers({"Content-Type: application/json"})
        @Get("{nextLink}")
        @ExpectedResponses({200})
        @UnexpectedResponseExceptionType(ManagementException.class)
        Mono<Response<OnlineDeploymentTrackedResourceArmPaginatedResult>> listNext(
            @PathParam(value = "nextLink", encoded = true) String nextLink,
            @HostParam("$host") String endpoint,
            @HeaderParam("Accept") String accept,
            Context context);
    }

    /**
     * List Inference Endpoint Deployments.
     *
     * @param endpointName Inference endpoint name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param orderBy Ordering of list.
     * @param top Top of list.
     * @param skip Continuation token for pagination.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a paginated list of OnlineDeployment entities.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private Mono<PagedResponse<OnlineDeploymentTrackedResourceInner>> listSinglePageAsync(
        String endpointName, String resourceGroupName, String workspaceName, String orderBy, Integer top, String skip) {
        if (this.client.getEndpoint() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getEndpoint() is required and cannot be null."));
        }
        if (endpointName == null) {
            return Mono.error(new IllegalArgumentException("Parameter endpointName is required and cannot be null."));
        }
        if (this.client.getSubscriptionId() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getSubscriptionId() is required and cannot be null."));
        }
        if (resourceGroupName == null) {
            return Mono
                .error(new IllegalArgumentException("Parameter resourceGroupName is required and cannot be null."));
        }
        if (workspaceName == null) {
            return Mono.error(new IllegalArgumentException("Parameter workspaceName is required and cannot be null."));
        }
        final String accept = "application/json";
        return FluxUtil
            .withContext(
                context ->
                    service
                        .list(
                            this.client.getEndpoint(),
                            endpointName,
                            this.client.getApiVersion(),
                            orderBy,
                            top,
                            skip,
                            this.client.getSubscriptionId(),
                            resourceGroupName,
                            workspaceName,
                            accept,
                            context))
            .<PagedResponse<OnlineDeploymentTrackedResourceInner>>map(
                res ->
                    new PagedResponseBase<>(
                        res.getRequest(),
                        res.getStatusCode(),
                        res.getHeaders(),
                        res.getValue().value(),
                        res.getValue().nextLink(),
                        null))
            .contextWrite(context -> context.putAll(FluxUtil.toReactorContext(this.client.getContext()).readOnly()));
    }

    /**
     * List Inference Endpoint Deployments.
     *
     * @param endpointName Inference endpoint name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param orderBy Ordering of list.
     * @param top Top of list.
     * @param skip Continuation token for pagination.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a paginated list of OnlineDeployment entities.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private Mono<PagedResponse<OnlineDeploymentTrackedResourceInner>> listSinglePageAsync(
        String endpointName,
        String resourceGroupName,
        String workspaceName,
        String orderBy,
        Integer top,
        String skip,
        Context context) {
        if (this.client.getEndpoint() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getEndpoint() is required and cannot be null."));
        }
        if (endpointName == null) {
            return Mono.error(new IllegalArgumentException("Parameter endpointName is required and cannot be null."));
        }
        if (this.client.getSubscriptionId() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getSubscriptionId() is required and cannot be null."));
        }
        if (resourceGroupName == null) {
            return Mono
                .error(new IllegalArgumentException("Parameter resourceGroupName is required and cannot be null."));
        }
        if (workspaceName == null) {
            return Mono.error(new IllegalArgumentException("Parameter workspaceName is required and cannot be null."));
        }
        final String accept = "application/json";
        context = this.client.mergeContext(context);
        return service
            .list(
                this.client.getEndpoint(),
                endpointName,
                this.client.getApiVersion(),
                orderBy,
                top,
                skip,
                this.client.getSubscriptionId(),
                resourceGroupName,
                workspaceName,
                accept,
                context)
            .map(
                res ->
                    new PagedResponseBase<>(
                        res.getRequest(),
                        res.getStatusCode(),
                        res.getHeaders(),
                        res.getValue().value(),
                        res.getValue().nextLink(),
                        null));
    }

    /**
     * List Inference Endpoint Deployments.
     *
     * @param endpointName Inference endpoint name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param orderBy Ordering of list.
     * @param top Top of list.
     * @param skip Continuation token for pagination.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a paginated list of OnlineDeployment entities.
     */
    @ServiceMethod(returns = ReturnType.COLLECTION)
    private PagedFlux<OnlineDeploymentTrackedResourceInner> listAsync(
        String endpointName, String resourceGroupName, String workspaceName, String orderBy, Integer top, String skip) {
        return new PagedFlux<>(
            () -> listSinglePageAsync(endpointName, resourceGroupName, workspaceName, orderBy, top, skip),
            nextLink -> listNextSinglePageAsync(nextLink));
    }

    /**
     * List Inference Endpoint Deployments.
     *
     * @param endpointName Inference endpoint name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a paginated list of OnlineDeployment entities.
     */
    @ServiceMethod(returns = ReturnType.COLLECTION)
    private PagedFlux<OnlineDeploymentTrackedResourceInner> listAsync(
        String endpointName, String resourceGroupName, String workspaceName) {
        final String orderBy = null;
        final Integer top = null;
        final String skip = null;
        return new PagedFlux<>(
            () -> listSinglePageAsync(endpointName, resourceGroupName, workspaceName, orderBy, top, skip),
            nextLink -> listNextSinglePageAsync(nextLink));
    }

    /**
     * List Inference Endpoint Deployments.
     *
     * @param endpointName Inference endpoint name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param orderBy Ordering of list.
     * @param top Top of list.
     * @param skip Continuation token for pagination.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a paginated list of OnlineDeployment entities.
     */
    @ServiceMethod(returns = ReturnType.COLLECTION)
    private PagedFlux<OnlineDeploymentTrackedResourceInner> listAsync(
        String endpointName,
        String resourceGroupName,
        String workspaceName,
        String orderBy,
        Integer top,
        String skip,
        Context context) {
        return new PagedFlux<>(
            () -> listSinglePageAsync(endpointName, resourceGroupName, workspaceName, orderBy, top, skip, context),
            nextLink -> listNextSinglePageAsync(nextLink, context));
    }

    /**
     * List Inference Endpoint Deployments.
     *
     * @param endpointName Inference endpoint name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a paginated list of OnlineDeployment entities.
     */
    @ServiceMethod(returns = ReturnType.COLLECTION)
    public PagedIterable<OnlineDeploymentTrackedResourceInner> list(
        String endpointName, String resourceGroupName, String workspaceName) {
        final String orderBy = null;
        final Integer top = null;
        final String skip = null;
        return new PagedIterable<>(listAsync(endpointName, resourceGroupName, workspaceName, orderBy, top, skip));
    }

    /**
     * List Inference Endpoint Deployments.
     *
     * @param endpointName Inference endpoint name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param orderBy Ordering of list.
     * @param top Top of list.
     * @param skip Continuation token for pagination.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a paginated list of OnlineDeployment entities.
     */
    @ServiceMethod(returns = ReturnType.COLLECTION)
    public PagedIterable<OnlineDeploymentTrackedResourceInner> list(
        String endpointName,
        String resourceGroupName,
        String workspaceName,
        String orderBy,
        Integer top,
        String skip,
        Context context) {
        return new PagedIterable<>(
            listAsync(endpointName, resourceGroupName, workspaceName, orderBy, top, skip, context));
    }

    /**
     * Delete Inference Endpoint Deployment (asynchronous).
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the completion.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private Mono<Response<Flux<ByteBuffer>>> deleteWithResponseAsync(
        String endpointName, String deploymentName, String resourceGroupName, String workspaceName) {
        if (this.client.getEndpoint() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getEndpoint() is required and cannot be null."));
        }
        if (endpointName == null) {
            return Mono.error(new IllegalArgumentException("Parameter endpointName is required and cannot be null."));
        }
        if (deploymentName == null) {
            return Mono.error(new IllegalArgumentException("Parameter deploymentName is required and cannot be null."));
        }
        if (this.client.getSubscriptionId() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getSubscriptionId() is required and cannot be null."));
        }
        if (resourceGroupName == null) {
            return Mono
                .error(new IllegalArgumentException("Parameter resourceGroupName is required and cannot be null."));
        }
        if (workspaceName == null) {
            return Mono.error(new IllegalArgumentException("Parameter workspaceName is required and cannot be null."));
        }
        final String accept = "application/json";
        return FluxUtil
            .withContext(
                context ->
                    service
                        .delete(
                            this.client.getEndpoint(),
                            endpointName,
                            deploymentName,
                            this.client.getApiVersion(),
                            this.client.getSubscriptionId(),
                            resourceGroupName,
                            workspaceName,
                            accept,
                            context))
            .contextWrite(context -> context.putAll(FluxUtil.toReactorContext(this.client.getContext()).readOnly()));
    }

    /**
     * Delete Inference Endpoint Deployment (asynchronous).
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the completion.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private Mono<Response<Flux<ByteBuffer>>> deleteWithResponseAsync(
        String endpointName, String deploymentName, String resourceGroupName, String workspaceName, Context context) {
        if (this.client.getEndpoint() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getEndpoint() is required and cannot be null."));
        }
        if (endpointName == null) {
            return Mono.error(new IllegalArgumentException("Parameter endpointName is required and cannot be null."));
        }
        if (deploymentName == null) {
            return Mono.error(new IllegalArgumentException("Parameter deploymentName is required and cannot be null."));
        }
        if (this.client.getSubscriptionId() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getSubscriptionId() is required and cannot be null."));
        }
        if (resourceGroupName == null) {
            return Mono
                .error(new IllegalArgumentException("Parameter resourceGroupName is required and cannot be null."));
        }
        if (workspaceName == null) {
            return Mono.error(new IllegalArgumentException("Parameter workspaceName is required and cannot be null."));
        }
        final String accept = "application/json";
        context = this.client.mergeContext(context);
        return service
            .delete(
                this.client.getEndpoint(),
                endpointName,
                deploymentName,
                this.client.getApiVersion(),
                this.client.getSubscriptionId(),
                resourceGroupName,
                workspaceName,
                accept,
                context);
    }

    /**
     * Delete Inference Endpoint Deployment (asynchronous).
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the completion.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private PollerFlux<PollResult<Void>, Void> beginDeleteAsync(
        String endpointName, String deploymentName, String resourceGroupName, String workspaceName) {
        Mono<Response<Flux<ByteBuffer>>> mono =
            deleteWithResponseAsync(endpointName, deploymentName, resourceGroupName, workspaceName);
        return this
            .client
            .<Void, Void>getLroResult(mono, this.client.getHttpPipeline(), Void.class, Void.class, Context.NONE);
    }

    /**
     * Delete Inference Endpoint Deployment (asynchronous).
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the completion.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private PollerFlux<PollResult<Void>, Void> beginDeleteAsync(
        String endpointName, String deploymentName, String resourceGroupName, String workspaceName, Context context) {
        context = this.client.mergeContext(context);
        Mono<Response<Flux<ByteBuffer>>> mono =
            deleteWithResponseAsync(endpointName, deploymentName, resourceGroupName, workspaceName, context);
        return this
            .client
            .<Void, Void>getLroResult(mono, this.client.getHttpPipeline(), Void.class, Void.class, context);
    }

    /**
     * Delete Inference Endpoint Deployment (asynchronous).
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the completion.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public SyncPoller<PollResult<Void>, Void> beginDelete(
        String endpointName, String deploymentName, String resourceGroupName, String workspaceName) {
        return beginDeleteAsync(endpointName, deploymentName, resourceGroupName, workspaceName).getSyncPoller();
    }

    /**
     * Delete Inference Endpoint Deployment (asynchronous).
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the completion.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public SyncPoller<PollResult<Void>, Void> beginDelete(
        String endpointName, String deploymentName, String resourceGroupName, String workspaceName, Context context) {
        return beginDeleteAsync(endpointName, deploymentName, resourceGroupName, workspaceName, context)
            .getSyncPoller();
    }

    /**
     * Delete Inference Endpoint Deployment (asynchronous).
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the completion.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private Mono<Void> deleteAsync(
        String endpointName, String deploymentName, String resourceGroupName, String workspaceName) {
        return beginDeleteAsync(endpointName, deploymentName, resourceGroupName, workspaceName)
            .last()
            .flatMap(this.client::getLroFinalResultOrError);
    }

    /**
     * Delete Inference Endpoint Deployment (asynchronous).
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the completion.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private Mono<Void> deleteAsync(
        String endpointName, String deploymentName, String resourceGroupName, String workspaceName, Context context) {
        return beginDeleteAsync(endpointName, deploymentName, resourceGroupName, workspaceName, context)
            .last()
            .flatMap(this.client::getLroFinalResultOrError);
    }

    /**
     * Delete Inference Endpoint Deployment (asynchronous).
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public void delete(String endpointName, String deploymentName, String resourceGroupName, String workspaceName) {
        deleteAsync(endpointName, deploymentName, resourceGroupName, workspaceName).block();
    }

    /**
     * Delete Inference Endpoint Deployment (asynchronous).
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public void delete(
        String endpointName, String deploymentName, String resourceGroupName, String workspaceName, Context context) {
        deleteAsync(endpointName, deploymentName, resourceGroupName, workspaceName, context).block();
    }

    /**
     * Get Inference Deployment Deployment.
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return inference Deployment Deployment.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private Mono<Response<OnlineDeploymentTrackedResourceInner>> getWithResponseAsync(
        String endpointName, String deploymentName, String resourceGroupName, String workspaceName) {
        if (this.client.getEndpoint() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getEndpoint() is required and cannot be null."));
        }
        if (endpointName == null) {
            return Mono.error(new IllegalArgumentException("Parameter endpointName is required and cannot be null."));
        }
        if (deploymentName == null) {
            return Mono.error(new IllegalArgumentException("Parameter deploymentName is required and cannot be null."));
        }
        if (this.client.getSubscriptionId() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getSubscriptionId() is required and cannot be null."));
        }
        if (resourceGroupName == null) {
            return Mono
                .error(new IllegalArgumentException("Parameter resourceGroupName is required and cannot be null."));
        }
        if (workspaceName == null) {
            return Mono.error(new IllegalArgumentException("Parameter workspaceName is required and cannot be null."));
        }
        final String accept = "application/json";
        return FluxUtil
            .withContext(
                context ->
                    service
                        .get(
                            this.client.getEndpoint(),
                            endpointName,
                            deploymentName,
                            this.client.getApiVersion(),
                            this.client.getSubscriptionId(),
                            resourceGroupName,
                            workspaceName,
                            accept,
                            context))
            .contextWrite(context -> context.putAll(FluxUtil.toReactorContext(this.client.getContext()).readOnly()));
    }

    /**
     * Get Inference Deployment Deployment.
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return inference Deployment Deployment.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private Mono<Response<OnlineDeploymentTrackedResourceInner>> getWithResponseAsync(
        String endpointName, String deploymentName, String resourceGroupName, String workspaceName, Context context) {
        if (this.client.getEndpoint() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getEndpoint() is required and cannot be null."));
        }
        if (endpointName == null) {
            return Mono.error(new IllegalArgumentException("Parameter endpointName is required and cannot be null."));
        }
        if (deploymentName == null) {
            return Mono.error(new IllegalArgumentException("Parameter deploymentName is required and cannot be null."));
        }
        if (this.client.getSubscriptionId() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getSubscriptionId() is required and cannot be null."));
        }
        if (resourceGroupName == null) {
            return Mono
                .error(new IllegalArgumentException("Parameter resourceGroupName is required and cannot be null."));
        }
        if (workspaceName == null) {
            return Mono.error(new IllegalArgumentException("Parameter workspaceName is required and cannot be null."));
        }
        final String accept = "application/json";
        context = this.client.mergeContext(context);
        return service
            .get(
                this.client.getEndpoint(),
                endpointName,
                deploymentName,
                this.client.getApiVersion(),
                this.client.getSubscriptionId(),
                resourceGroupName,
                workspaceName,
                accept,
                context);
    }

    /**
     * Get Inference Deployment Deployment.
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return inference Deployment Deployment.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private Mono<OnlineDeploymentTrackedResourceInner> getAsync(
        String endpointName, String deploymentName, String resourceGroupName, String workspaceName) {
        return getWithResponseAsync(endpointName, deploymentName, resourceGroupName, workspaceName)
            .flatMap(
                (Response<OnlineDeploymentTrackedResourceInner> res) -> {
                    if (res.getValue() != null) {
                        return Mono.just(res.getValue());
                    } else {
                        return Mono.empty();
                    }
                });
    }

    /**
     * Get Inference Deployment Deployment.
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return inference Deployment Deployment.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public OnlineDeploymentTrackedResourceInner get(
        String endpointName, String deploymentName, String resourceGroupName, String workspaceName) {
        return getAsync(endpointName, deploymentName, resourceGroupName, workspaceName).block();
    }

    /**
     * Get Inference Deployment Deployment.
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return inference Deployment Deployment.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<OnlineDeploymentTrackedResourceInner> getWithResponse(
        String endpointName, String deploymentName, String resourceGroupName, String workspaceName, Context context) {
        return getWithResponseAsync(endpointName, deploymentName, resourceGroupName, workspaceName, context).block();
    }

    /**
     * Update Online Deployment (asynchronous).
     *
     * @param endpointName Online Endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body Online Endpoint entity to apply during operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private Mono<Response<Flux<ByteBuffer>>> updateWithResponseAsync(
        String endpointName,
        String deploymentName,
        String resourceGroupName,
        String workspaceName,
        PartialOnlineDeploymentPartialTrackedResource body) {
        if (this.client.getEndpoint() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getEndpoint() is required and cannot be null."));
        }
        if (endpointName == null) {
            return Mono.error(new IllegalArgumentException("Parameter endpointName is required and cannot be null."));
        }
        if (deploymentName == null) {
            return Mono.error(new IllegalArgumentException("Parameter deploymentName is required and cannot be null."));
        }
        if (this.client.getSubscriptionId() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getSubscriptionId() is required and cannot be null."));
        }
        if (resourceGroupName == null) {
            return Mono
                .error(new IllegalArgumentException("Parameter resourceGroupName is required and cannot be null."));
        }
        if (workspaceName == null) {
            return Mono.error(new IllegalArgumentException("Parameter workspaceName is required and cannot be null."));
        }
        if (body == null) {
            return Mono.error(new IllegalArgumentException("Parameter body is required and cannot be null."));
        } else {
            body.validate();
        }
        final String accept = "application/json";
        return FluxUtil
            .withContext(
                context ->
                    service
                        .update(
                            this.client.getEndpoint(),
                            endpointName,
                            deploymentName,
                            this.client.getApiVersion(),
                            this.client.getSubscriptionId(),
                            resourceGroupName,
                            workspaceName,
                            body,
                            accept,
                            context))
            .contextWrite(context -> context.putAll(FluxUtil.toReactorContext(this.client.getContext()).readOnly()));
    }

    /**
     * Update Online Deployment (asynchronous).
     *
     * @param endpointName Online Endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body Online Endpoint entity to apply during operation.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private Mono<Response<Flux<ByteBuffer>>> updateWithResponseAsync(
        String endpointName,
        String deploymentName,
        String resourceGroupName,
        String workspaceName,
        PartialOnlineDeploymentPartialTrackedResource body,
        Context context) {
        if (this.client.getEndpoint() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getEndpoint() is required and cannot be null."));
        }
        if (endpointName == null) {
            return Mono.error(new IllegalArgumentException("Parameter endpointName is required and cannot be null."));
        }
        if (deploymentName == null) {
            return Mono.error(new IllegalArgumentException("Parameter deploymentName is required and cannot be null."));
        }
        if (this.client.getSubscriptionId() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getSubscriptionId() is required and cannot be null."));
        }
        if (resourceGroupName == null) {
            return Mono
                .error(new IllegalArgumentException("Parameter resourceGroupName is required and cannot be null."));
        }
        if (workspaceName == null) {
            return Mono.error(new IllegalArgumentException("Parameter workspaceName is required and cannot be null."));
        }
        if (body == null) {
            return Mono.error(new IllegalArgumentException("Parameter body is required and cannot be null."));
        } else {
            body.validate();
        }
        final String accept = "application/json";
        context = this.client.mergeContext(context);
        return service
            .update(
                this.client.getEndpoint(),
                endpointName,
                deploymentName,
                this.client.getApiVersion(),
                this.client.getSubscriptionId(),
                resourceGroupName,
                workspaceName,
                body,
                accept,
                context);
    }

    /**
     * Update Online Deployment (asynchronous).
     *
     * @param endpointName Online Endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body Online Endpoint entity to apply during operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private PollerFlux<PollResult<OnlineDeploymentTrackedResourceInner>, OnlineDeploymentTrackedResourceInner>
        beginUpdateAsync(
            String endpointName,
            String deploymentName,
            String resourceGroupName,
            String workspaceName,
            PartialOnlineDeploymentPartialTrackedResource body) {
        Mono<Response<Flux<ByteBuffer>>> mono =
            updateWithResponseAsync(endpointName, deploymentName, resourceGroupName, workspaceName, body);
        return this
            .client
            .<OnlineDeploymentTrackedResourceInner, OnlineDeploymentTrackedResourceInner>getLroResult(
                mono,
                this.client.getHttpPipeline(),
                OnlineDeploymentTrackedResourceInner.class,
                OnlineDeploymentTrackedResourceInner.class,
                Context.NONE);
    }

    /**
     * Update Online Deployment (asynchronous).
     *
     * @param endpointName Online Endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body Online Endpoint entity to apply during operation.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private PollerFlux<PollResult<OnlineDeploymentTrackedResourceInner>, OnlineDeploymentTrackedResourceInner>
        beginUpdateAsync(
            String endpointName,
            String deploymentName,
            String resourceGroupName,
            String workspaceName,
            PartialOnlineDeploymentPartialTrackedResource body,
            Context context) {
        context = this.client.mergeContext(context);
        Mono<Response<Flux<ByteBuffer>>> mono =
            updateWithResponseAsync(endpointName, deploymentName, resourceGroupName, workspaceName, body, context);
        return this
            .client
            .<OnlineDeploymentTrackedResourceInner, OnlineDeploymentTrackedResourceInner>getLroResult(
                mono,
                this.client.getHttpPipeline(),
                OnlineDeploymentTrackedResourceInner.class,
                OnlineDeploymentTrackedResourceInner.class,
                context);
    }

    /**
     * Update Online Deployment (asynchronous).
     *
     * @param endpointName Online Endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body Online Endpoint entity to apply during operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public SyncPoller<PollResult<OnlineDeploymentTrackedResourceInner>, OnlineDeploymentTrackedResourceInner>
        beginUpdate(
            String endpointName,
            String deploymentName,
            String resourceGroupName,
            String workspaceName,
            PartialOnlineDeploymentPartialTrackedResource body) {
        return beginUpdateAsync(endpointName, deploymentName, resourceGroupName, workspaceName, body).getSyncPoller();
    }

    /**
     * Update Online Deployment (asynchronous).
     *
     * @param endpointName Online Endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body Online Endpoint entity to apply during operation.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public SyncPoller<PollResult<OnlineDeploymentTrackedResourceInner>, OnlineDeploymentTrackedResourceInner>
        beginUpdate(
            String endpointName,
            String deploymentName,
            String resourceGroupName,
            String workspaceName,
            PartialOnlineDeploymentPartialTrackedResource body,
            Context context) {
        return beginUpdateAsync(endpointName, deploymentName, resourceGroupName, workspaceName, body, context)
            .getSyncPoller();
    }

    /**
     * Update Online Deployment (asynchronous).
     *
     * @param endpointName Online Endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body Online Endpoint entity to apply during operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private Mono<OnlineDeploymentTrackedResourceInner> updateAsync(
        String endpointName,
        String deploymentName,
        String resourceGroupName,
        String workspaceName,
        PartialOnlineDeploymentPartialTrackedResource body) {
        return beginUpdateAsync(endpointName, deploymentName, resourceGroupName, workspaceName, body)
            .last()
            .flatMap(this.client::getLroFinalResultOrError);
    }

    /**
     * Update Online Deployment (asynchronous).
     *
     * @param endpointName Online Endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body Online Endpoint entity to apply during operation.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private Mono<OnlineDeploymentTrackedResourceInner> updateAsync(
        String endpointName,
        String deploymentName,
        String resourceGroupName,
        String workspaceName,
        PartialOnlineDeploymentPartialTrackedResource body,
        Context context) {
        return beginUpdateAsync(endpointName, deploymentName, resourceGroupName, workspaceName, body, context)
            .last()
            .flatMap(this.client::getLroFinalResultOrError);
    }

    /**
     * Update Online Deployment (asynchronous).
     *
     * @param endpointName Online Endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body Online Endpoint entity to apply during operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public OnlineDeploymentTrackedResourceInner update(
        String endpointName,
        String deploymentName,
        String resourceGroupName,
        String workspaceName,
        PartialOnlineDeploymentPartialTrackedResource body) {
        return updateAsync(endpointName, deploymentName, resourceGroupName, workspaceName, body).block();
    }

    /**
     * Update Online Deployment (asynchronous).
     *
     * @param endpointName Online Endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body Online Endpoint entity to apply during operation.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public OnlineDeploymentTrackedResourceInner update(
        String endpointName,
        String deploymentName,
        String resourceGroupName,
        String workspaceName,
        PartialOnlineDeploymentPartialTrackedResource body,
        Context context) {
        return updateAsync(endpointName, deploymentName, resourceGroupName, workspaceName, body, context).block();
    }

    /**
     * Create or update Inference Endpoint Deployment (asynchronous).
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body Inference Endpoint entity to apply during operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private Mono<Response<Flux<ByteBuffer>>> createOrUpdateWithResponseAsync(
        String endpointName,
        String deploymentName,
        String resourceGroupName,
        String workspaceName,
        OnlineDeploymentTrackedResourceInner body) {
        if (this.client.getEndpoint() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getEndpoint() is required and cannot be null."));
        }
        if (endpointName == null) {
            return Mono.error(new IllegalArgumentException("Parameter endpointName is required and cannot be null."));
        }
        if (deploymentName == null) {
            return Mono.error(new IllegalArgumentException("Parameter deploymentName is required and cannot be null."));
        }
        if (this.client.getSubscriptionId() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getSubscriptionId() is required and cannot be null."));
        }
        if (resourceGroupName == null) {
            return Mono
                .error(new IllegalArgumentException("Parameter resourceGroupName is required and cannot be null."));
        }
        if (workspaceName == null) {
            return Mono.error(new IllegalArgumentException("Parameter workspaceName is required and cannot be null."));
        }
        if (body == null) {
            return Mono.error(new IllegalArgumentException("Parameter body is required and cannot be null."));
        } else {
            body.validate();
        }
        final String accept = "application/json";
        return FluxUtil
            .withContext(
                context ->
                    service
                        .createOrUpdate(
                            this.client.getEndpoint(),
                            endpointName,
                            deploymentName,
                            this.client.getApiVersion(),
                            this.client.getSubscriptionId(),
                            resourceGroupName,
                            workspaceName,
                            body,
                            accept,
                            context))
            .contextWrite(context -> context.putAll(FluxUtil.toReactorContext(this.client.getContext()).readOnly()));
    }

    /**
     * Create or update Inference Endpoint Deployment (asynchronous).
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body Inference Endpoint entity to apply during operation.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private Mono<Response<Flux<ByteBuffer>>> createOrUpdateWithResponseAsync(
        String endpointName,
        String deploymentName,
        String resourceGroupName,
        String workspaceName,
        OnlineDeploymentTrackedResourceInner body,
        Context context) {
        if (this.client.getEndpoint() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getEndpoint() is required and cannot be null."));
        }
        if (endpointName == null) {
            return Mono.error(new IllegalArgumentException("Parameter endpointName is required and cannot be null."));
        }
        if (deploymentName == null) {
            return Mono.error(new IllegalArgumentException("Parameter deploymentName is required and cannot be null."));
        }
        if (this.client.getSubscriptionId() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getSubscriptionId() is required and cannot be null."));
        }
        if (resourceGroupName == null) {
            return Mono
                .error(new IllegalArgumentException("Parameter resourceGroupName is required and cannot be null."));
        }
        if (workspaceName == null) {
            return Mono.error(new IllegalArgumentException("Parameter workspaceName is required and cannot be null."));
        }
        if (body == null) {
            return Mono.error(new IllegalArgumentException("Parameter body is required and cannot be null."));
        } else {
            body.validate();
        }
        final String accept = "application/json";
        context = this.client.mergeContext(context);
        return service
            .createOrUpdate(
                this.client.getEndpoint(),
                endpointName,
                deploymentName,
                this.client.getApiVersion(),
                this.client.getSubscriptionId(),
                resourceGroupName,
                workspaceName,
                body,
                accept,
                context);
    }

    /**
     * Create or update Inference Endpoint Deployment (asynchronous).
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body Inference Endpoint entity to apply during operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private PollerFlux<PollResult<OnlineDeploymentTrackedResourceInner>, OnlineDeploymentTrackedResourceInner>
        beginCreateOrUpdateAsync(
            String endpointName,
            String deploymentName,
            String resourceGroupName,
            String workspaceName,
            OnlineDeploymentTrackedResourceInner body) {
        Mono<Response<Flux<ByteBuffer>>> mono =
            createOrUpdateWithResponseAsync(endpointName, deploymentName, resourceGroupName, workspaceName, body);
        return this
            .client
            .<OnlineDeploymentTrackedResourceInner, OnlineDeploymentTrackedResourceInner>getLroResult(
                mono,
                this.client.getHttpPipeline(),
                OnlineDeploymentTrackedResourceInner.class,
                OnlineDeploymentTrackedResourceInner.class,
                Context.NONE);
    }

    /**
     * Create or update Inference Endpoint Deployment (asynchronous).
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body Inference Endpoint entity to apply during operation.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private PollerFlux<PollResult<OnlineDeploymentTrackedResourceInner>, OnlineDeploymentTrackedResourceInner>
        beginCreateOrUpdateAsync(
            String endpointName,
            String deploymentName,
            String resourceGroupName,
            String workspaceName,
            OnlineDeploymentTrackedResourceInner body,
            Context context) {
        context = this.client.mergeContext(context);
        Mono<Response<Flux<ByteBuffer>>> mono =
            createOrUpdateWithResponseAsync(
                endpointName, deploymentName, resourceGroupName, workspaceName, body, context);
        return this
            .client
            .<OnlineDeploymentTrackedResourceInner, OnlineDeploymentTrackedResourceInner>getLroResult(
                mono,
                this.client.getHttpPipeline(),
                OnlineDeploymentTrackedResourceInner.class,
                OnlineDeploymentTrackedResourceInner.class,
                context);
    }

    /**
     * Create or update Inference Endpoint Deployment (asynchronous).
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body Inference Endpoint entity to apply during operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public SyncPoller<PollResult<OnlineDeploymentTrackedResourceInner>, OnlineDeploymentTrackedResourceInner>
        beginCreateOrUpdate(
            String endpointName,
            String deploymentName,
            String resourceGroupName,
            String workspaceName,
            OnlineDeploymentTrackedResourceInner body) {
        return beginCreateOrUpdateAsync(endpointName, deploymentName, resourceGroupName, workspaceName, body)
            .getSyncPoller();
    }

    /**
     * Create or update Inference Endpoint Deployment (asynchronous).
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body Inference Endpoint entity to apply during operation.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public SyncPoller<PollResult<OnlineDeploymentTrackedResourceInner>, OnlineDeploymentTrackedResourceInner>
        beginCreateOrUpdate(
            String endpointName,
            String deploymentName,
            String resourceGroupName,
            String workspaceName,
            OnlineDeploymentTrackedResourceInner body,
            Context context) {
        return beginCreateOrUpdateAsync(endpointName, deploymentName, resourceGroupName, workspaceName, body, context)
            .getSyncPoller();
    }

    /**
     * Create or update Inference Endpoint Deployment (asynchronous).
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body Inference Endpoint entity to apply during operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private Mono<OnlineDeploymentTrackedResourceInner> createOrUpdateAsync(
        String endpointName,
        String deploymentName,
        String resourceGroupName,
        String workspaceName,
        OnlineDeploymentTrackedResourceInner body) {
        return beginCreateOrUpdateAsync(endpointName, deploymentName, resourceGroupName, workspaceName, body)
            .last()
            .flatMap(this.client::getLroFinalResultOrError);
    }

    /**
     * Create or update Inference Endpoint Deployment (asynchronous).
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body Inference Endpoint entity to apply during operation.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private Mono<OnlineDeploymentTrackedResourceInner> createOrUpdateAsync(
        String endpointName,
        String deploymentName,
        String resourceGroupName,
        String workspaceName,
        OnlineDeploymentTrackedResourceInner body,
        Context context) {
        return beginCreateOrUpdateAsync(endpointName, deploymentName, resourceGroupName, workspaceName, body, context)
            .last()
            .flatMap(this.client::getLroFinalResultOrError);
    }

    /**
     * Create or update Inference Endpoint Deployment (asynchronous).
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body Inference Endpoint entity to apply during operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public OnlineDeploymentTrackedResourceInner createOrUpdate(
        String endpointName,
        String deploymentName,
        String resourceGroupName,
        String workspaceName,
        OnlineDeploymentTrackedResourceInner body) {
        return createOrUpdateAsync(endpointName, deploymentName, resourceGroupName, workspaceName, body).block();
    }

    /**
     * Create or update Inference Endpoint Deployment (asynchronous).
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName Inference Endpoint Deployment name.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body Inference Endpoint entity to apply during operation.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public OnlineDeploymentTrackedResourceInner createOrUpdate(
        String endpointName,
        String deploymentName,
        String resourceGroupName,
        String workspaceName,
        OnlineDeploymentTrackedResourceInner body,
        Context context) {
        return createOrUpdateAsync(endpointName, deploymentName, resourceGroupName, workspaceName, body, context)
            .block();
    }

    /**
     * Polls an Endpoint operation.
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName The name and identifier for the endpoint.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body The request containing parameters for retrieving logs.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private Mono<Response<DeploymentLogsInner>> getLogsWithResponseAsync(
        String endpointName,
        String deploymentName,
        String resourceGroupName,
        String workspaceName,
        DeploymentLogsRequest body) {
        if (this.client.getEndpoint() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getEndpoint() is required and cannot be null."));
        }
        if (endpointName == null) {
            return Mono.error(new IllegalArgumentException("Parameter endpointName is required and cannot be null."));
        }
        if (deploymentName == null) {
            return Mono.error(new IllegalArgumentException("Parameter deploymentName is required and cannot be null."));
        }
        if (this.client.getSubscriptionId() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getSubscriptionId() is required and cannot be null."));
        }
        if (resourceGroupName == null) {
            return Mono
                .error(new IllegalArgumentException("Parameter resourceGroupName is required and cannot be null."));
        }
        if (workspaceName == null) {
            return Mono.error(new IllegalArgumentException("Parameter workspaceName is required and cannot be null."));
        }
        if (body == null) {
            return Mono.error(new IllegalArgumentException("Parameter body is required and cannot be null."));
        } else {
            body.validate();
        }
        final String accept = "application/json";
        return FluxUtil
            .withContext(
                context ->
                    service
                        .getLogs(
                            this.client.getEndpoint(),
                            endpointName,
                            deploymentName,
                            this.client.getApiVersion(),
                            this.client.getSubscriptionId(),
                            resourceGroupName,
                            workspaceName,
                            body,
                            accept,
                            context))
            .contextWrite(context -> context.putAll(FluxUtil.toReactorContext(this.client.getContext()).readOnly()));
    }

    /**
     * Polls an Endpoint operation.
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName The name and identifier for the endpoint.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body The request containing parameters for retrieving logs.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private Mono<Response<DeploymentLogsInner>> getLogsWithResponseAsync(
        String endpointName,
        String deploymentName,
        String resourceGroupName,
        String workspaceName,
        DeploymentLogsRequest body,
        Context context) {
        if (this.client.getEndpoint() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getEndpoint() is required and cannot be null."));
        }
        if (endpointName == null) {
            return Mono.error(new IllegalArgumentException("Parameter endpointName is required and cannot be null."));
        }
        if (deploymentName == null) {
            return Mono.error(new IllegalArgumentException("Parameter deploymentName is required and cannot be null."));
        }
        if (this.client.getSubscriptionId() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getSubscriptionId() is required and cannot be null."));
        }
        if (resourceGroupName == null) {
            return Mono
                .error(new IllegalArgumentException("Parameter resourceGroupName is required and cannot be null."));
        }
        if (workspaceName == null) {
            return Mono.error(new IllegalArgumentException("Parameter workspaceName is required and cannot be null."));
        }
        if (body == null) {
            return Mono.error(new IllegalArgumentException("Parameter body is required and cannot be null."));
        } else {
            body.validate();
        }
        final String accept = "application/json";
        context = this.client.mergeContext(context);
        return service
            .getLogs(
                this.client.getEndpoint(),
                endpointName,
                deploymentName,
                this.client.getApiVersion(),
                this.client.getSubscriptionId(),
                resourceGroupName,
                workspaceName,
                body,
                accept,
                context);
    }

    /**
     * Polls an Endpoint operation.
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName The name and identifier for the endpoint.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body The request containing parameters for retrieving logs.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private Mono<DeploymentLogsInner> getLogsAsync(
        String endpointName,
        String deploymentName,
        String resourceGroupName,
        String workspaceName,
        DeploymentLogsRequest body) {
        return getLogsWithResponseAsync(endpointName, deploymentName, resourceGroupName, workspaceName, body)
            .flatMap(
                (Response<DeploymentLogsInner> res) -> {
                    if (res.getValue() != null) {
                        return Mono.just(res.getValue());
                    } else {
                        return Mono.empty();
                    }
                });
    }

    /**
     * Polls an Endpoint operation.
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName The name and identifier for the endpoint.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body The request containing parameters for retrieving logs.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public DeploymentLogsInner getLogs(
        String endpointName,
        String deploymentName,
        String resourceGroupName,
        String workspaceName,
        DeploymentLogsRequest body) {
        return getLogsAsync(endpointName, deploymentName, resourceGroupName, workspaceName, body).block();
    }

    /**
     * Polls an Endpoint operation.
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName The name and identifier for the endpoint.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body The request containing parameters for retrieving logs.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<DeploymentLogsInner> getLogsWithResponse(
        String endpointName,
        String deploymentName,
        String resourceGroupName,
        String workspaceName,
        DeploymentLogsRequest body,
        Context context) {
        return getLogsWithResponseAsync(endpointName, deploymentName, resourceGroupName, workspaceName, body, context)
            .block();
    }

    /**
     * Get the next page of items.
     *
     * @param nextLink The nextLink parameter.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a paginated list of OnlineDeployment entities.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private Mono<PagedResponse<OnlineDeploymentTrackedResourceInner>> listNextSinglePageAsync(String nextLink) {
        if (nextLink == null) {
            return Mono.error(new IllegalArgumentException("Parameter nextLink is required and cannot be null."));
        }
        if (this.client.getEndpoint() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getEndpoint() is required and cannot be null."));
        }
        final String accept = "application/json";
        return FluxUtil
            .withContext(context -> service.listNext(nextLink, this.client.getEndpoint(), accept, context))
            .<PagedResponse<OnlineDeploymentTrackedResourceInner>>map(
                res ->
                    new PagedResponseBase<>(
                        res.getRequest(),
                        res.getStatusCode(),
                        res.getHeaders(),
                        res.getValue().value(),
                        res.getValue().nextLink(),
                        null))
            .contextWrite(context -> context.putAll(FluxUtil.toReactorContext(this.client.getContext()).readOnly()));
    }

    /**
     * Get the next page of items.
     *
     * @param nextLink The nextLink parameter.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a paginated list of OnlineDeployment entities.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    private Mono<PagedResponse<OnlineDeploymentTrackedResourceInner>> listNextSinglePageAsync(
        String nextLink, Context context) {
        if (nextLink == null) {
            return Mono.error(new IllegalArgumentException("Parameter nextLink is required and cannot be null."));
        }
        if (this.client.getEndpoint() == null) {
            return Mono
                .error(
                    new IllegalArgumentException(
                        "Parameter this.client.getEndpoint() is required and cannot be null."));
        }
        final String accept = "application/json";
        context = this.client.mergeContext(context);
        return service
            .listNext(nextLink, this.client.getEndpoint(), accept, context)
            .map(
                res ->
                    new PagedResponseBase<>(
                        res.getRequest(),
                        res.getStatusCode(),
                        res.getHeaders(),
                        res.getValue().value(),
                        res.getValue().nextLink(),
                        null));
    }
}
