// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.resourcemanager.machinelearningservices.fluent;

import com.azure.core.annotation.ReturnType;
import com.azure.core.annotation.ServiceMethod;
import com.azure.core.http.rest.PagedIterable;
import com.azure.core.http.rest.Response;
import com.azure.core.util.Context;
import com.azure.resourcemanager.machinelearningservices.fluent.models.BatchDeploymentTrackedResourceInner;

/** An instance of this class provides access to all the operations defined in BatchDeploymentsClient. */
public interface BatchDeploymentsClient {
    /**
     * Creates a batch inference deployment.
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName The identifier for the Batch inference deployment.
     * @param resourceGroupName Name of the resource group in which workspace is located.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    BatchDeploymentTrackedResourceInner createOrUpdate(
        String endpointName, String deploymentName, String resourceGroupName, String workspaceName);

    /**
     * Creates a batch inference deployment.
     *
     * @param endpointName Inference endpoint name.
     * @param deploymentName The identifier for the Batch inference deployment.
     * @param resourceGroupName Name of the resource group in which workspace is located.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param body Batch inference deployment definition object.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    Response<BatchDeploymentTrackedResourceInner> createOrUpdateWithResponse(
        String endpointName,
        String deploymentName,
        String resourceGroupName,
        String workspaceName,
        BatchDeploymentTrackedResourceInner body,
        Context context);

    /**
     * Gets a batch inference deployment by id.
     *
     * @param endpointName Endpoint name.
     * @param deploymentName The identifier for the Batch deployments.
     * @param resourceGroupName Name of the resource group in which workspace is located.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a batch inference deployment by id.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    BatchDeploymentTrackedResourceInner get(
        String endpointName, String deploymentName, String resourceGroupName, String workspaceName);

    /**
     * Gets a batch inference deployment by id.
     *
     * @param endpointName Endpoint name.
     * @param deploymentName The identifier for the Batch deployments.
     * @param resourceGroupName Name of the resource group in which workspace is located.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a batch inference deployment by id.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    Response<BatchDeploymentTrackedResourceInner> getWithResponse(
        String endpointName, String deploymentName, String resourceGroupName, String workspaceName, Context context);

    /**
     * Delete Batch Inference deployment.
     *
     * @param endpointName Endpoint name.
     * @param deploymentName Inference deployment identifier.
     * @param resourceGroupName Name of the resource group in which workspace is located.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    void delete(String endpointName, String deploymentName, String resourceGroupName, String workspaceName);

    /**
     * Delete Batch Inference deployment.
     *
     * @param endpointName Endpoint name.
     * @param deploymentName Inference deployment identifier.
     * @param resourceGroupName Name of the resource group in which workspace is located.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    Response<Void> deleteWithResponse(
        String endpointName, String deploymentName, String resourceGroupName, String workspaceName, Context context);

    /**
     * Lists Batch inference deployments in the workspace.
     *
     * @param endpointName Endpoint name.
     * @param resourceGroupName Name of the resource group in which workspace is located.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a paginated list of BatchDeployment entities.
     */
    @ServiceMethod(returns = ReturnType.COLLECTION)
    PagedIterable<BatchDeploymentTrackedResourceInner> list(
        String endpointName, String resourceGroupName, String workspaceName);

    /**
     * Lists Batch inference deployments in the workspace.
     *
     * @param endpointName Endpoint name.
     * @param resourceGroupName Name of the resource group in which workspace is located.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param skiptoken Continuation token for pagination.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a paginated list of BatchDeployment entities.
     */
    @ServiceMethod(returns = ReturnType.COLLECTION)
    PagedIterable<BatchDeploymentTrackedResourceInner> list(
        String endpointName, String resourceGroupName, String workspaceName, String skiptoken, Context context);
}
